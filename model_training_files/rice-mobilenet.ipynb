{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1891018,"sourceType":"datasetVersion","datasetId":1126682}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport pandas as pd\nfrom collections import Counter\nimport pickle\n\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:28:21.853607Z","iopub.execute_input":"2025-08-01T06:28:21.853848Z","iopub.status.idle":"2025-08-01T06:28:30.621201Z","shell.execute_reply.started":"2025-08-01T06:28:21.853824Z","shell.execute_reply":"2025-08-01T06:28:30.620420Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/nutrientdeficiencysymptomsinrice/rice_plant_lacks_nutrients'\nMODEL_SAVE_PATH = 'rice_mobilenet_from_scratch.pth'\nCLASS_MAPPING_PATH = 'class_mapping.pkl'\n\nIMG_SIZE = 224\nNUM_CLASSES = 3 \n\nBATCH_SIZE = 64\nEPOCHS = 50\nLEARNING_RATE = 0.001\nEARLY_STOPPING_PATIENCE = 10 \nLR_SCHEDULER_PATIENCE = 5  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:28:30.622039Z","iopub.execute_input":"2025-08-01T06:28:30.622388Z","iopub.status.idle":"2025-08-01T06:28:30.626598Z","shell.execute_reply.started":"2025-08-01T06:28:30.622369Z","shell.execute_reply":"2025-08-01T06:28:30.626076Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class RiceMobileNetV2(nn.Module):\n    def __init__(self, num_classes=3, from_scratch=True):\n        super(RiceMobileNetV2, self).__init__()\n        \n        if from_scratch:\n            print(\"Initializing model with random weights (training from scratch).\")\n            weights = None\n        else:\n            print(\"Initializing model with pre-trained ImageNet weights.\")\n            weights = models.MobileNet_V2_Weights.IMAGENET1K_V1\n            \n        self.mobilenet_v2 = models.mobilenet_v2(weights=weights)\n        \n        num_features = self.mobilenet_v2.classifier[1].in_features\n        \n        self.mobilenet_v2.classifier = nn.Sequential(\n            nn.Dropout(p=0.3),\n            nn.Linear(num_features, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(p=0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, x):\n        return self.mobilenet_v2(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(IMG_SIZE),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Scale to [-1, 1]\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(IMG_SIZE + 32),\n        transforms.CenterCrop(IMG_SIZE),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n    ]),\n}\n\nprint(\"Loading and splitting data...\")\nfull_dataset = datasets.ImageFolder(DATA_DIR)\nclass_names = full_dataset.classes\nprint(f\"Classes found: {class_names}\")\n\ntrain_val_indices, test_indices = train_test_split(\n    list(range(len(full_dataset.targets))),\n    test_size=0.15,\n    stratify=full_dataset.targets,\n    random_state=42\n)\ntrain_indices, val_indices = train_test_split(\n    train_val_indices,\n    test_size=0.176, # Approx. 15% of the original dataset (0.15 / 0.85)\n    stratify=[full_dataset.targets[i] for i in train_val_indices],\n    random_state=42\n)\n\ntrain_dataset = torch.utils.data.Subset(full_dataset, train_indices)\nval_dataset = torch.utils.data.Subset(full_dataset, val_indices)\ntest_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n\ntrain_dataset.dataset.transform = data_transforms['train']\n# For validation and test, we need to clone the dataset to apply the correct transform\nval_dataset_transformed = torch.utils.data.Subset(datasets.ImageFolder(DATA_DIR, transform=data_transforms['val']), val_indices)\ntest_dataset_transformed = torch.utils.data.Subset(datasets.ImageFolder(DATA_DIR, transform=data_transforms['val']), test_indices)\n\ndataloaders = {\n    'train': torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n    'val': torch.utils.data.DataLoader(val_dataset_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=2),\n    'test': torch.utils.data.DataLoader(test_dataset_transformed, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n}\n\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset), 'test': len(test_dataset)}\nprint(f\"Dataset sizes: {dataset_sizes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Calculating class weights for handling imbalance...\")\ntrain_labels = [full_dataset.targets[i] for i in train_indices]\nclass_counts = Counter(train_labels)\ntotal_samples = len(train_labels)\n\nclass_weights = torch.tensor(\n    [total_samples / class_counts[i] for i in range(len(class_names))],\n    dtype=torch.float32\n)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nclass_weights = class_weights.to(device)\n\nprint(f\"Calculated class weights: {class_weights}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    \n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n\n    best_acc = 0.0\n    epochs_no_improve = 0\n    \n    model.to(device)\n    print(f\"Training on device: {device}\")\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'train':\n                history['train_loss'].append(epoch_loss)\n                history['train_acc'].append(epoch_acc.cpu())\n            else:\n                history['val_loss'].append(epoch_loss)\n                history['val_acc'].append(epoch_acc.cpu())\n                \n                scheduler.step(epoch_loss)\n\n                if epoch_acc > best_acc:\n                    print(f\"Validation accuracy improved ({best_acc:.4f} --> {epoch_acc:.4f}). Saving model...\")\n                    best_acc = epoch_acc\n                    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n                    epochs_no_improve = 0\n                else:\n                    epochs_no_improve += 1\n        \n        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n            print(f\"\\nEarly stopping triggered after {epoch+1} epochs.\")\n            break\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n    \n    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    return model, history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_ft = RiceMobileNetV2(num_classes=NUM_CLASSES, from_scratch=True)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\noptimizer = optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=LR_SCHEDULER_PATIENCE, verbose=True)\n\nbest_model, history = train_model(model_ft, criterion, optimizer, scheduler, num_epochs=EPOCHS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nfig.suptitle('PyTorch Model Training History')\n\nax1.plot(history['train_loss'], label='Train Loss')\nax1.plot(history['val_loss'], label='Validation Loss')\nax1.set_title('Loss vs. Epochs')\nax1.set_xlabel('Epochs')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True)\n\nax2.plot(history['train_acc'], label='Train Accuracy')\nax2.plot(history['val_acc'], label='Validation Accuracy')\nax2.set_title('Accuracy vs. Epochs')\nax2.set_xlabel('Epochs')\nax2.set_ylabel('Accuracy')\nax2.legend()\nax2.grid(True)\n\nplt.savefig('training_curves_pytorch.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Evaluating on Test Set ---\")\nbest_model.eval() \ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for inputs, labels in dataloaders['test']:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = best_model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names))\n\ncm = confusion_matrix(y_true, y_pred)\ndf_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\nplt.figure(figsize=(8, 6))\nsns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='Blues')\nplt.title('Confusion Matrix on Test Set')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.savefig('confusion_matrix_pytorch.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_mapping = {i: name for i, name in enumerate(class_names)}\n\nwith open(CLASS_MAPPING_PATH, 'wb') as f:\n    pickle.dump(class_mapping, f)\n    \nprint(f\"âœ… Class mapping saved to: {CLASS_MAPPING_PATH}\")\nprint(\"Mapping details:\", class_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}